{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#For merging and rezising the Masks\n",
    "\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "#Change path here\n",
    "path = r\"/Users/deepitapai/Documents/TUM/MLMI Project/MontgomerySet_Original/\"\n",
    "\n",
    "\n",
    "def resizeImg(im):\n",
    "    image_resized = im.resize((224,224), Image.ANTIALIAS)\n",
    "\n",
    "    return image_resized\n",
    "\n",
    "def mergeMasks(path,pic):\n",
    "\n",
    "    try :\n",
    "        img_left = Image.open(path+\"ManualMask/leftMask/\"+pic)\n",
    "        img_right = Image.open(path+\"ManualMask/rightMask/\"+pic)\n",
    "\n",
    "        width, height = img_left.size\n",
    "        l_top, l_left, l_right, l_bottom = 0,0,int(width/2),height\n",
    "        r_top, r_left, r_right, r_bottom = int(width/2)+1,0,width,height\n",
    "        img_left = img_left.crop((l_top, l_left, l_right, l_bottom))\n",
    "        img_right = img_right.crop((r_top, r_left, r_right, r_bottom))\n",
    "\n",
    "        img_new = Image.new('L',(width, height),'black')\n",
    "        img_new.paste(img_left,(l_top, l_left, l_right, l_bottom))\n",
    "        img_new.paste(img_right,(r_top, r_left, r_right, r_bottom))\n",
    "        \n",
    "    except IOError:\n",
    "        print (\"cannot merge images for \", pic)\n",
    "            \n",
    "    return(img_new)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    #Merge and Resize Masks\n",
    "    if not os.path.exists(path+\"/MergedMask/\"):\n",
    "        os.makedirs(path+\"/MergedMask/\")\n",
    "\n",
    "    for pic in os.listdir(path+\"ManualMask/leftMask\"):\n",
    "        if pic.endswith(\".png\"): \n",
    "            img_merged = mergeMasks(path,pic)\n",
    "            img_resized = resizeImg(img_merged)  \n",
    "            img_resized.save(path+\"/MergedMask/\"+pic)\n",
    "    \n",
    "    #Resize CXRs\n",
    "    if not os.path.exists(path+\"/ResizedCXR/\"):\n",
    "        os.makedirs(path+\"/ResizedCXR/\")\n",
    "\n",
    "    for pic in os.listdir(path+\"/CXR_png\"):\n",
    "        if pic.endswith(\".png\"): \n",
    "            img = Image.open(path+\"/CXR_png/\"+pic)\n",
    "            img_resized = resizeImg(img)  \n",
    "            img_resized.save(path+\"/ResizedCXR/\"+pic)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Montgomery Dataset in train, test, validation sets and writing the necessary text files\n",
    "\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "#Change path here\n",
    "path = r\"/Users/deepitapai/Documents/TUM/MLMIProject/dataset_montgomery disease_labelled/\"\n",
    "#Change splits here\n",
    "train_frac = 0.7\n",
    "test_frac = 0.2\n",
    "val_frac = 0.1 #rest for validation\n",
    "\n",
    "\n",
    "def create_textfiles():\n",
    "\n",
    "    train= open(path+\"train.txt\",\"w+\")\n",
    "    test= open(path+\"test.txt\",\"w+\")\n",
    "    val= open(path+\"val.txt\",\"w+\")\n",
    "    \n",
    "    return train,test,val\n",
    "\n",
    "def get_imgnames():\n",
    "    path_CXR = path + \"/ResizedCXR\"\n",
    "    imglist = []\n",
    "    for img in os.listdir(path_CXR):  #getting all image names\n",
    "        imglist.append(img)\n",
    "\n",
    "    return imglist\n",
    "\n",
    "def split(imglist):\n",
    "    random.shuffle(imglist)\n",
    "    sets = len(imglist)\n",
    "    #print(sets)\n",
    "    train_sets= int(sets*train_frac)\n",
    "    test_sets= int(sets*test_frac+train_sets)\n",
    "    #print(train_sets)\n",
    "    #print(test_sets)\n",
    "    train_list = imglist[:train_sets]\n",
    "    test_list = imglist[train_sets:test_sets]\n",
    "    val_list = imglist[test_sets:sets]\n",
    "    \n",
    "    return train_list,test_list,val_list\n",
    "    \n",
    "def write_textfiles(imglist,textfile):\n",
    "    for img in imglist:\n",
    "        textfile.write(path+\"/ResizedCXR/\"+img+\" \"+path+\"/MergedMask_annotated/\"+img+\"\\n\")\n",
    "    \n",
    "    textfile.close() \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    train,test,val = create_textfiles()\n",
    "    imglist = get_imgnames()\n",
    "    train_list,test_list,val_list = split(imglist)\n",
    "    write_textfiles(train_list,train)\n",
    "    write_textfiles(test_list,test)\n",
    "    write_textfiles(val_list,val)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
